# -*- coding: utf-8 -*-
"""Vector Addition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G-w0h52l1Ui1h8PxS8uzcjBYqpw-v1Zm
"""

!nvcc --version

!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git

# Commented out IPython magic to ensure Python compatibility.
# %load_ext nvcc4jupyter

"""**CUDA HELLO WORLD**"""

# Commented out IPython magic to ensure Python compatibility.
# %%cuda
# #include <stdio.h>
# 
# __global__ void hello(){
#     printf("Hello from block: %u, thread: %u\n", blockIdx.x, threadIdx.x);
# }
# 
# int main(){
#     hello<<<2, 2>>>();
#     cudaDeviceSynchronize();
# }

"""**1) n blocks and one thread per block (In this example n=6)**"""

# Commented out IPython magic to ensure Python compatibility.
# %%cuda
# #include<stdio.h>
# #include<cuda.h>
# 
# __global__ void arradd(int *x,int *y, int *z)    //kernel definition
# {
#   int id=blockIdx.x;
# /* blockIdx.x gives the respective block id which starts from 0 */
#   z[id]=x[id]+y[id];
# }
# 
# int main()
# {
#     int a[6]={1,2,3,4,5,6};
#     int b[6]={1,2,3,4,5,6};
#     int c[6];
#     int *d,*e,*f;
#     int i;
#     /*
#     printf("\n Enter six elements of first array\n");
#     for(i=0;i<6;i++)
#     {
#         scanf("%d",&a[i]);
#     }
#     printf("\n Enter six elements of second array\n");
#         for(i=0;i<6;i++)
#         {
#             scanf("%d",&b[i]);
#         }
#     */
# 
# /* cudaMalloc() allocates memory from Global memory on GPU */
#     cudaMalloc((void **)&d,6*sizeof(int));
#     cudaMalloc((void **)&e,6*sizeof(int));
#     cudaMalloc((void **)&f,6*sizeof(int));
# 
# /* cudaMemcpy() copies the contents from destination to source. Here destination is GPU(d,e) and source is CPU(a,b) */
#  cudaMemcpy(d,a,6*sizeof(int),cudaMemcpyHostToDevice);
# 
# 
#  cudaMemcpy(e,b,6*sizeof(int),cudaMemcpyHostToDevice);
# 
# /* call to kernel. Here 6 is number of blocks, 1 is the number of threads per block and d,e,f are the arguments */
# arradd<<<6,1>>>(d,e,f);
# 
# /* Here we are copying content from GPU(Device) to CPU(Host) */
#  cudaMemcpy(c,f,6*sizeof(int),cudaMemcpyDeviceToHost);
# 
# printf("\nSum of two arrays:\n ");
#     for(i=0;i<6;i++)
#     {
#         printf("%d\t",c[i]);
#     }
# 
# /* Free the memory allocated to pointers d,e,f */
#     cudaFree(d);
#     cudaFree(e);
#     cudaFree(f);
# 
#     return 0;
# }

"""**2) One block and n threads in that block (In this example n=6)**"""

# Commented out IPython magic to ensure Python compatibility.
# %%cuda
# #include<stdio.h>
# #include<cuda.h>
# __global__ void arradd(int *x,int *y, int *z)
# {
#     int id=threadIdx.x;
# /* threadIdx.x gives the respective thread id which starts from 0 */
#     z[id]=x[id]+y[id];
# }
# int main()
# {
#     int a[6]={1,2,3,4,5,6};
#     int b[6]={1,2,3,4,5,6};
#     int c[6];
#     int *d,*e,*f;
#     int i;
# 
#     /*
#     printf("\n Enter six elements of first array\n");
#     for(i=0;i<6;i++)
#     {
#         scanf("%d",&a[i]);
#     }
#     printf("\n Enter six elements of second array\n");
#         for(i=0;i<6;i++)
#         {
#             scanf("%d",&b[i]);
#         }
#     */
# 
#     cudaMalloc((void **)&d,6*sizeof(int));
#     cudaMalloc((void **)&e,6*sizeof(int));
#     cudaMalloc((void **)&f,6*sizeof(int));
#  cudaMemcpy(d,a,6*sizeof(int),cudaMemcpyHostToDevice);   cudaMemcpy(e,b,6*sizeof(int),cudaMemcpyHostToDevice);
#     arradd<<<1,6>>>(d,e,f);
#  cudaMemcpy(c,f,6*sizeof(int),cudaMemcpyDeviceToHost);
#     printf("\nSum of two arrays:\n ");
#     for(i=0;i<6;i++)
#     {
#         printf("%d\t",c[i]);
#     }
#     cudaFree(d);
#     cudaFree(e);
#     cudaFree(f);
#     return 0;
# }